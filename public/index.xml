<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mike Yu</title>
    <link>https://mike-yu.com/</link>
    <description>Recent content on Mike Yu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://mike-yu.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>trying out docopt</title>
      <link>https://mike-yu.com/posts/trying-out-docopt/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://mike-yu.com/posts/trying-out-docopt/</guid>
      <description>trying out docopt    In my last post I created a very small command line interface (CLI) using argparse, which is a built in Python module. This time around I&amp;rsquo;m going to use the same code as before but instead of argparse I&amp;rsquo;ll use a third-party module calle docopt.
I got this idea from a great talk called From Python script to Open Source Project by Michał Karzyński. It has a lot of great content about putting together a fully-fledged open source Python project and I recommend watching the whole thing.</description>
    </item>
    
    <item>
      <title>argparse is cool</title>
      <link>https://mike-yu.com/posts/argparse-is-cool/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://mike-yu.com/posts/argparse-is-cool/</guid>
      <description>argparse is cool    I need to copy files between S3 buckets on a regular basis for my job. The aws command line tool is great but I forget flags often&amp;hellip;and usually the same ones over and over. What if I made a custom version of aws s3 cp that was simpler and fit the majority of my copy usecases?
Well, here it is in 43 lines (with proper spacing) using argparse:</description>
    </item>
    
    <item>
      <title>About Mike</title>
      <link>https://mike-yu.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mike-yu.com/about/</guid>
      <description>Fun facts     Currently Reading: My Year Abroad by Chang-rae Lee Favorite team: Mariners (see The History of the Seattle Mariners) Famously featured in the Embers Grille Big Triple Challenge commercial  Career    import json with open(&amp;#39;resume.json&amp;#39;) as f: resume = json.load(f) for exp in resume: print(f&amp;#39;{exp[&amp;#34;state&amp;#34;]} -&amp;gt; {exp[&amp;#34;job&amp;#34;]}&amp;#39;) &amp;gt;&amp;gt;&amp;gt; IL -&amp;gt; Music Major &amp;gt;&amp;gt;&amp;gt; GA -&amp;gt; Project Manager &amp;gt;&amp;gt;&amp;gt; WA -&amp;gt; Business Analyst &amp;gt;&amp;gt;&amp;gt; WA -&amp;gt; Solution Architect &amp;gt;&amp;gt;&amp;gt; WA -&amp;gt; Data Analyst &amp;gt;&amp;gt;&amp;gt; WA -&amp;gt; Senior Data Analyst </description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://mike-yu.com/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mike-yu.com/projects/</guid>
      <description>Recipes    whatsfordinner.recipes
Based on Recipes by jeffThompson and modifications by kvpsky. It is a static website, hosted by Netlify in my case, with my favorite recipes and some editorial notes. Helpful for last minute dinner planning.
fantasy football    repo and docs
Repo to learn NFL fantasy football strategy and practice some data engineering skills along the way.</description>
    </item>
    
  </channel>
</rss>
